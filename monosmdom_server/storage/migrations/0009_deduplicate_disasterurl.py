# Generated by Django 4.2.6 on 2023-11-12 20:51

from django.db import migrations
from django.db.models import Count, Max


def forwards_func(apps, schema_editor):
    DisasterUrl = apps.get_model("storage", "DisasterUrl")
    Url = apps.get_model("storage", "Url")
    # Determine duplicated Urls:
    duplicated_urls = Url.objects.filter().annotate(count=Count("disasterurl"), newest=Max("disasterurl__id")).filter(count__gt=1).values_list("id", "count", "newest")
    # Remove duplicates:
    printed_anything = False
    for url_id, count, newest_durl in duplicated_urls:
        if not printed_anything:
            printed_anything = True
            # We interrupt the nicely formatted output of ./manage.py migrate,
            # so at least make it less terrible by starting a new line:
            print()
        print(f"    Deleting {count - 1} of {count} DisasterUrl entries for Url.id={url_id}")
        DisasterUrl.objects.exclude(id=newest_durl).filter(url_id=url_id).delete()
    # Model is now ready to make the "url_id" column unique in the next migration.


def reverse_func(apps, schema_editor):
    # Nothing to do!
    # The data are already consistent, no need to "undelete" the duplicates.
    # Besides, we lost the information anyway which rows were duplicated how often.
    pass


class Migration(migrations.Migration):
    dependencies = [
        ("storage", "0008_increase_maximum_url_length"),
    ]

    operations = [migrations.RunPython(forwards_func, reverse_func, elidable=True)]
